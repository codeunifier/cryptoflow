<div class="l-text-center">
  <span class="about">About</span>
</div>
<div class="about-para">
  <p>Cryptoflow was created to predict the prices of cryptocurrencies like Bitcoin utilizing the Python library TensorFlow; hence the name, Crypto-flow.</p>
  <p>I developed this site to merely demonstrate a simple, working neural network making simple predictions using past data. Here, 
    I'll pull back the curtain a little and explain the engine running the predictions.</p>
  <p>The method I'm using to make predictions was initially based off a method used by many, many people all over the internet 
    mainly because its results can appear to be very optimistic. Below is the graph of a model based on this method making 
    predictions on data for bitcoin prices. At first glance, it seems like this model can make predictions with incredible accuracy. 
    However, when viewed closely, what's actually happening is this model is simply spitting out the previous day's price slightly 
    offset.</p>
  <div class="about-image-container l-text-center">
    <img class="about-image image-wide" src="../../assets/images/graph.png">
    <img class="about-image image-wide" src="../../assets/images/graph-zoom.png">
  </div>

  <h3>Economics</h3>
  <p>Rafael Schultze-Kraft goes into much more detail about this in 
    <a href="https://hackernoon.com/dont-be-fooled-deceptive-cryptocurrency-price-predictions-using-deep-learning-bf27e4837151">
      his explanation
    </a> 
    of this popular yet deceptive form of predicting the prices of cryptocurrencies.</p>
  <p>At first I didn't quite realize what was going on. Each implementation of a neural network trying to attempt this task went 
    a completely different way, creating different neural network models based off of different kinds of datasets, and it was 
    all very confusing and overwhelming trying to sift through it all without understanding much about machine learning.</p>
  <p>Even now, my model is nowhere near perfect, and I wouldn't even say it's accurate. When I started this project, I thought 
    it would be relatively simple as far as a neural network goes. There's only one output (a predicted price) and a series of 
    simple inputs (previous prices). This method, however, is 
    <a href="https://medium.com/apteo/stock-prices-dont-predict-stock-prices-bbf3e421bedf">not an accurate way</a> 
    to predict fluctuations in prices as volatile as cryptocurrency.</p>
  <p>This is a <a href="https://en.wikipedia.org/wiki/Technical_analysis">Technical Analysis</a> approach, forecasting future prices 
    based on the study of past data. The unfortunate reality is that cryptocurrencies adhere closer to 
    <a href="https://www.investopedia.com/terms/r/randomwalktheory.asp">Random Walk Theory</a>, which suggests that changes in stock
    prices are somewhat random and independent of each other, so they can't be used to predict future fluctuations. There are many, 
    many factors that influence the direction stock prices will go, and cryptocurrencies are typically more volatile than stocks.</p>

  <h3>Neural Networks</h3>
  <p><a href="https://www.tensorflow.org/">TensorFlow</a> is a library dedicated to creating neural networks for machine learning. 
    At the beginning of this project, I knew nothing of how machine learning actually worked nor had I any idea of how to actually 
    develop any knid of learning model. I am also not an economist; I know little about what influences stock market prices or 
    other volatile, fluctuating investments. If you haven't figured out already, the predictions here should absolutely be taken 
    with a grain of salt and not used in sincere consideration of the state of the market.</p>
  <p>The model I'm using is called a Long-Short Term Memory (LSTM) network. Without going too deep down the technical rabbit hole, 
    I'll just say that an LSTM network focuses on using past data collectively as it considers its next prediction. As a neural 
    network cycles through the data, it typically "forgets" about past data as soon as it makes a prediction with those inputs. 
    LSTM networks hold on to that data a little longer, containing the data outside the normal flow of the recurrent network. 
    For the eggheads, here's a depiction of the model that might make more sense (although it doesn't to me, to be honest).</p>
  <div class="about-image-container l-text-center">
    <img class="about-image image-tall" src="../../assets/images/math.png">
  </div>
  <p>A neural network is able to learn by going through this mathematical process through what's called an "epoch," or a single 
    iteration through all of the data. During training, the model will make predictions and verify its predictions against another
    set of data to see how close it got, and then make adjustments for the next prediction. Using calculus, the network is able to 
    keep track of the difference between its prediction and the actual value, which is called loss. The network seeks to keep 
    adjusting itself to minimize its loss, which it does in steps. As it continues, it takes steps to get closer and closer to 
    the minimum loss.
  </p>

  <h3>Code</h3>
  <p>Alright, time to dive into some code. This is probably where I'm going to start losing people, but here it goes. Below is 
    the model for the neural network I'm using. I've got two LSTM layers and a single Dense layer, compressing the output from 
    the LSTM layers into a single value (a price). I wrapped it in a CryptoModel class for ease of use throughout my program. 
    Getting to this point was a bit of a struggle. It took a lot of tweaking of several variables to finally get something 
    that seemed accurate.</p>
  <pre>
    <code>
  class CryptoModel:
    __model = None

    def create(self, shape):
      units = 50
      self.__model = keras.models.Sequential()

      self.__model.add(keras.layers.LSTM(units, return_sequences=True, input_shape=(shape[1], shape[2])))   # first LSTM layer
      self.__model.add(keras.layers.LSTM(units, input_shape=(shape[1], shape[2])))                          # second LSTM layer
      self.__model.add(keras.layers.Dense(1)) #1 = a single output node                                     # dense layer
      self.__model.compile(loss="mse", optimizer="adam", metrics=['accuracy'])

    def train(self, train_x, train_y, test_x, test_y):
      return self.__model.fit(train_x, train_y, epochs=100, batch_size=200, validation_data=(test_x, test_y), verbose=0, shuffle=False)
    
    def predict(self, x):
      return self.__model.predict(x)
    </code>
  </pre>
  <p>At first, my model only had a single LSTM layer, and I was calculating loss by the Mean Aboslute Error (mae). The mae is 
    calculated by taking the average magnitude of the errors in a set of predictions. In Layman's terms, it's the average of 
    how wrong each prediction was. The network uses this value of loss to make better predictions in the next iteration.
  </p>
  <p>This approach worked...sort of. Below is a graph of the predictions against actual values and a graph showing the loss over 
    each iteration. The steeper the loss's descent and the lower the loss plateaus, the better. Ideally, we would want no loss 
    at all, indicating highly accurate predictions.
  </p>
  <div class="about-image-container l-text-center">
    <img class="about-image image-wide" src="../../assets/images/graph-layer-1.png">
    <img class="about-image image-wide" src="../../assets/images/loss-layer-1.png">
  </div>
  <p>Obviously, some improvements could be made. At this point, I adjusted the number of epochs the model would cycle through 
    and added the second LSTM layer, and below are my results.
  </p>
  <div class="about-image-container l-text-center">
    <img class="about-image image-wide" src="../../assets/images/graph-layer-2.png">
    <img class="about-image image-wide" src="../../assets/images/loss-layer-2.png">
  </div>
  <p>Definitely better, but still not quite as accurate as it could be. The issue here is that the model is overfitting the data. 
    Essentially, this means that the model is fitting a particular data set too closely, so when new data comes in, it's not as 
    accurate. It's like it's learned something wrong and can't get that wrong idea out of its head. So, to help prevent overfitting, 
    I halved the number of epochs and switched the loss metric to the Root Mean Squared Error (rmse). The rmse uses mae in its 
    calculation, but then it takes the square root of the average of squared differences between the prediction and the actual 
    value. A little complicated to follow, but my end results look pretty promising.
  </p>
  <div class="about-image-container l-text-center">
    <img class="about-image image-wide" src="../../assets/images/graph-current.png">
    <img class="about-image image-wide" src="../../assets/images/loss-current.png">
  </div>
</div>
<div class="blank-space">
</div>